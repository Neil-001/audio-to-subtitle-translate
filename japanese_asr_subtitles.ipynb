{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "220543da",
      "metadata": {
        "id": "220543da"
      },
      "source": [
        "# üéôÔ∏è Japanese Audio ‚Üí SRT Subtitles (JP + EN)\n",
        "\n",
        "This notebook:\n",
        "1. **Transcribes** uploaded Japanese audio using [Qwen/Qwen3-ASR-1.7B](https://huggingface.co/Qwen/Qwen3-ASR-1.7B) with word-level timestamps via the ForcedAligner\n",
        "2. **Generates** an SRT subtitle file from the transcription\n",
        "3. **Translates** the Japanese SRT to English using [Helsinki-NLP/opus-mt-ja-en](https://huggingface.co/Helsinki-NLP/opus-mt-ja-en) or Gemini\n",
        "\n",
        "**Requirements:** A Colab runtime with a **T4 GPU** (free tier works).\n",
        "\n",
        "> ‚ö†Ô∏è Make sure you've selected **Runtime ‚Üí Change runtime type ‚Üí T4 GPU** before running."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LTe9ZS_JZbQ-",
      "metadata": {
        "id": "LTe9ZS_JZbQ-"
      },
      "source": [
        "## 0 ¬∑ CONFIG\n",
        "\n",
        "Audio Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Vh6XyYsVZbqi",
      "metadata": {
        "id": "Vh6XyYsVZbqi"
      },
      "outputs": [],
      "source": [
        "# ‚ö†Ô∏è IMPORTANT ‚ö†Ô∏è\n",
        "# Path to the file to transcribe ‚Äî Supported formats:\n",
        "# .wav, .mp3, .flac, .ogg, .m4a, etc.\n",
        "AUDIO_PATH = \"ja_audio.mp3\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kz5ddNOpfVrv",
      "metadata": {
        "id": "kz5ddNOpfVrv"
      },
      "source": [
        "Technical Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WbhfwMkTfW0h",
      "metadata": {
        "id": "WbhfwMkTfW0h"
      },
      "outputs": [],
      "source": [
        "# Chunk length (seconds) ‚Äî Each audio chunk is processed separately\n",
        "# to fit in GPU memory. Shorter = less VRAM but more chunks.\n",
        "# 20 s works on a free-tier T4 (15 GB). Increase if you have more VRAM.\n",
        "CHUNK_SEC = 200\n",
        "\n",
        "# Maximum batch size for the ASR Model\n",
        "MAX_INFERENCE_BATCH_SIZE = 32  # TEST IF 32 WORKS, CHANGE TO 1 AGAIN IF NOT\n",
        "\n",
        "# Gemini translation batch size ‚Äî Number of subtitle lines sent\n",
        "# per API call. Larger = fewer calls but longer prompts.\n",
        "GEMINI_BATCH_SIZE = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1c7cff5",
      "metadata": {
        "id": "b1c7cff5"
      },
      "source": [
        "## 1 ¬∑ Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9933680e",
      "metadata": {
        "id": "9933680e"
      },
      "outputs": [],
      "source": [
        "!pip install -q qwen-asr transformers sentencepiece sacremoses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KTlr4jWHtWmj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTlr4jWHtWmj",
        "outputId": "3806f40b-d6f4-4abf-ebf1-f7011c4eda24"
      },
      "outputs": [],
      "source": [
        "!pip install -U flash-attn --no-build-isolation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41672cc7",
      "metadata": {
        "id": "41672cc7"
      },
      "source": [
        "## 2 ¬∑ Upload Japanese Audio File\n",
        "\n",
        "Supported formats: `.wav`, `.mp3`, `.flac`, `.ogg`, `.m4a`, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bd319ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "3bd319ef",
        "outputId": "c3703591-3f88-418e-b54e-e44732cb4e75"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Preview the uploaded audio\n",
        "if AUDIO_PATH and os.path.exists(AUDIO_PATH):\n",
        "    display(Audio(AUDIO_PATH))\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Please upload an audio file in the cell above first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7600d6d4",
      "metadata": {
        "id": "7600d6d4"
      },
      "source": [
        "## 3 ¬∑ Transcribe with Qwen3-ASR-1.7B\n",
        "\n",
        "To fit on a T4 (15 GB VRAM), we run ASR and alignment as **two separate steps** so both models are never loaded at the same time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "816bc4f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "d55e7b10d1544ecc8503cdf363732622",
            "9c0c0f539341452a9ea60137b28cb249",
            "92b941db825d40a5a88c8954cff53dbb",
            "aa7a8cfe307c413b92607e4cf1754ffe",
            "030fbd75958d40f3bfb6986b632ca4f3",
            "2edae9b923f545c2ae09464fa18dd73f",
            "aaecbd66f31246ddb27ebf19d50694a2",
            "deb1e97276664d26a647a4c2681cac99",
            "b142015ef28340f9a7b6b0c571cd9297",
            "44de2f6aa35f49109a55e4ad78d52268",
            "b82a844a83e94c3db3e37d2583edd546"
          ]
        },
        "id": "816bc4f7",
        "outputId": "23a2224f-2eb9-45d1-dad1-8c8ef11fa4ad"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import librosa\n",
        "from qwen_asr import Qwen3ASRModel\n",
        "\n",
        "# Help PyTorch reuse freed VRAM fragments\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "assert AUDIO_PATH and os.path.exists(AUDIO_PATH), (\n",
        "    \"No audio file found. Run the upload cell above first.\"\n",
        ")\n",
        "\n",
        "# --- Load and split audio manually ---\n",
        "# The audio tower's attention is O(n¬≤) on sequence length, so we split\n",
        "# into short segments and feed each one individually.\n",
        "SR = 16_000  # qwen-asr expects 16 kHz\n",
        "\n",
        "print(f\"Loading audio: {os.path.basename(AUDIO_PATH)} ‚Ä¶\")\n",
        "full_wav, _ = librosa.load(AUDIO_PATH, sr=SR, mono=True)\n",
        "total_dur = len(full_wav) / SR\n",
        "print(f\"Duration: {total_dur:.1f} s  ({total_dur / 60:.1f} min)\")\n",
        "\n",
        "chunk_samples = CHUNK_SEC * SR\n",
        "audio_chunks = []\n",
        "for start in range(0, len(full_wav), chunk_samples):\n",
        "    chunk = full_wav[start : start + chunk_samples]\n",
        "    if len(chunk) < SR // 2:  # skip tiny tail < 0.5 s\n",
        "        continue\n",
        "    audio_chunks.append((float(start) / SR, chunk))\n",
        "\n",
        "print(f\"Split into {len(audio_chunks)} chunks of ‚â§{CHUNK_SEC} s each.\")\n",
        "\n",
        "# --- Load ASR model ---\n",
        "print(\"\\nLoading Qwen3-ASR-1.7B ‚Ä¶\")\n",
        "asr_model = Qwen3ASRModel.from_pretrained(\n",
        "    \"Qwen/Qwen3-ASR-1.7B\",\n",
        "    dtype=torch.bfloat16,\n",
        "    device_map=\"cuda:0\",\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        "    max_inference_batch_size=MAX_INFERENCE_BATCH_SIZE,\n",
        "    max_new_tokens=4096,\n",
        ")\n",
        "print(\"‚úÖ ASR model loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a45c3e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a45c3e5",
        "outputId": "158e06ba-089c-437f-8504-1a63cf77af31"
      },
      "outputs": [],
      "source": [
        "# Transcribe each chunk individually to stay within T4 VRAM\n",
        "all_texts = []\n",
        "for i, (offset, chunk_wav) in enumerate(audio_chunks):\n",
        "    print(\n",
        "        f\"  Chunk {i + 1}/{len(audio_chunks)}  \"\n",
        "        f\"[{offset:.1f}s ‚Äì {offset + len(chunk_wav) / SR:.1f}s] ‚Ä¶\",\n",
        "        end=\" \",\n",
        "    )\n",
        "    r = asr_model.transcribe(\n",
        "        audio=(chunk_wav, SR),\n",
        "        language=\"Japanese\",\n",
        "        return_time_stamps=False,\n",
        "    )\n",
        "    text = r[0].text.strip()\n",
        "    all_texts.append(text)\n",
        "    print(text[:80])\n",
        "\n",
        "transcribed_text = \"\".join(all_texts)\n",
        "print(f\"\\n{'‚îÄ' * 60}\")\n",
        "print(f\"Full transcription ({len(transcribed_text)} chars):\\n{transcribed_text}\")\n",
        "\n",
        "# Free ASR model before loading the aligner\n",
        "del asr_model\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "print(\"\\n‚úÖ ASR model unloaded ‚Äî GPU memory freed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xjC-KHE52MCg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjC-KHE52MCg",
        "outputId": "6579dbbe-3d21-45a1-be95-f4d1936bc183"
      },
      "outputs": [],
      "source": [
        "# --- Step 2: Forced Aligner for word-level timestamps ---\n",
        "from dataclasses import replace\n",
        "from qwen_asr import Qwen3ForcedAligner\n",
        "\n",
        "print(\"Loading Qwen3-ForcedAligner-0.6B ‚Ä¶\")\n",
        "aligner = Qwen3ForcedAligner.from_pretrained(\n",
        "    \"Qwen/Qwen3-ForcedAligner-0.6B\",\n",
        "    dtype=torch.bfloat16,\n",
        "    device_map=\"cuda:0\",\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        ")\n",
        "print(\"‚úÖ Aligner loaded.\")\n",
        "\n",
        "# Align each chunk separately (same chunking as ASR) and shift timestamps\n",
        "print(\"Aligning timestamps ‚Ä¶\")\n",
        "time_stamps = []\n",
        "for i, (offset, chunk_wav) in enumerate(audio_chunks):\n",
        "    chunk_text = all_texts[i]\n",
        "    if not chunk_text.strip():\n",
        "        continue\n",
        "    print(f\"  Aligning chunk {i + 1}/{len(audio_chunks)} ‚Ä¶\")\n",
        "    alignment = aligner.align(\n",
        "        audio=(chunk_wav, SR),\n",
        "        text=chunk_text,\n",
        "        language=\"Japanese\",\n",
        "    )\n",
        "    # Shift timestamps by the chunk's offset (stamps are frozen dataclasses)\n",
        "    for stamp in alignment[0]:\n",
        "        shifted = replace(\n",
        "            stamp,\n",
        "            start_time=stamp.start_time + offset,\n",
        "            end_time=stamp.end_time + offset,\n",
        "        )\n",
        "        time_stamps.append(shifted)\n",
        "\n",
        "print(f\"\\nTimestamp segments: {len(time_stamps)}\")\n",
        "if time_stamps:\n",
        "    print(\n",
        "        f\"First: {time_stamps[0].text} [{time_stamps[0].start_time:.2f}s ‚Äì {time_stamps[0].end_time:.2f}s]\"\n",
        "    )\n",
        "\n",
        "# Free aligner\n",
        "del aligner\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "print(\"\\n‚úÖ Aligner unloaded ‚Äî GPU memory freed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0a3baa9",
      "metadata": {
        "id": "c0a3baa9"
      },
      "source": [
        "## 4 ¬∑ Generate SRT Subtitles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71c5731a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71c5731a",
        "outputId": "ef4ace6c-a53c-4775-8eb1-7ed12deb232d"
      },
      "outputs": [],
      "source": [
        "from datetime import timedelta\n",
        "\n",
        "\n",
        "def format_srt_time(seconds: float) -> str:\n",
        "    \"\"\"Convert seconds to SRT timestamp format: HH:MM:SS,mmm\"\"\"\n",
        "    td = timedelta(seconds=seconds)\n",
        "    total_seconds = int(td.total_seconds())\n",
        "    hours = total_seconds // 3600\n",
        "    minutes = (total_seconds % 3600) // 60\n",
        "    secs = total_seconds % 60\n",
        "    millis = int(td.microseconds / 1000)\n",
        "    return f\"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}\"\n",
        "\n",
        "\n",
        "def group_timestamps_to_subtitles(\n",
        "    stamps, max_chars: int = 40, max_duration: float = 7.0, gap_threshold: float = 0.6\n",
        "):\n",
        "    \"\"\"\n",
        "    Group word-level timestamps into subtitle segments.\n",
        "\n",
        "    Args:\n",
        "        stamps: list of timestamp objects with .text, .start_time, .end_time\n",
        "        max_chars: max characters per subtitle line\n",
        "        max_duration: max duration (seconds) per subtitle\n",
        "        gap_threshold: silence gap (seconds) that forces a new subtitle\n",
        "    \"\"\"\n",
        "    if not stamps:\n",
        "        return []\n",
        "\n",
        "    subtitles = []\n",
        "    current_text = \"\"\n",
        "    current_start = stamps[0].start_time\n",
        "    current_end = stamps[0].end_time\n",
        "\n",
        "    for i, stamp in enumerate(stamps):\n",
        "        # Decide whether to start a new subtitle\n",
        "        start_new = False\n",
        "        if i == 0:\n",
        "            current_text = stamp.text\n",
        "            current_start = stamp.start_time\n",
        "            current_end = stamp.end_time\n",
        "            continue\n",
        "\n",
        "        # Check gap between previous and current word\n",
        "        gap = stamp.start_time - current_end\n",
        "        new_duration = stamp.end_time - current_start\n",
        "        new_len = len(current_text) + len(stamp.text)\n",
        "\n",
        "        if gap > gap_threshold or new_duration > max_duration or new_len > max_chars:\n",
        "            start_new = True\n",
        "\n",
        "        if start_new:\n",
        "            subtitles.append((current_start, current_end, current_text.strip()))\n",
        "            current_text = stamp.text\n",
        "            current_start = stamp.start_time\n",
        "            current_end = stamp.end_time\n",
        "        else:\n",
        "            current_text += stamp.text\n",
        "            current_end = stamp.end_time\n",
        "\n",
        "    # Don't forget the last segment\n",
        "    if current_text.strip():\n",
        "        subtitles.append((current_start, current_end, current_text.strip()))\n",
        "\n",
        "    return subtitles\n",
        "\n",
        "\n",
        "def build_srt(subtitles) -> str:\n",
        "    \"\"\"Build SRT string from list of (start, end, text) tuples.\"\"\"\n",
        "    lines = []\n",
        "    for idx, (start, end, text) in enumerate(subtitles, 1):\n",
        "        lines.append(str(idx))\n",
        "        lines.append(f\"{format_srt_time(start)} --> {format_srt_time(end)}\")\n",
        "        lines.append(text)\n",
        "        lines.append(\"\")  # blank line separator\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "\n",
        "# Build Japanese SRT\n",
        "subtitles_ja = group_timestamps_to_subtitles(time_stamps)\n",
        "\n",
        "srt_ja = build_srt(subtitles_ja)\n",
        "\n",
        "# Save\n",
        "base_name = os.path.splitext(os.path.basename(AUDIO_PATH))[0]\n",
        "srt_ja_path = f\"/content/{base_name}_ja.srt\"\n",
        "with open(srt_ja_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(srt_ja)\n",
        "\n",
        "print(f\"‚úÖ Japanese SRT saved to: {srt_ja_path}\")\n",
        "print(f\"   {len(subtitles_ja)} subtitle segments\\n\")\n",
        "print(\"--- Preview (first 10 segments) ---\")\n",
        "print(\"\\n\".join(srt_ja.split(\"\\n\")[:40]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7602d2d1",
      "metadata": {
        "id": "7602d2d1"
      },
      "source": [
        "## 5 ¬∑ Translate Subtitles to English (opus-mt, local)\n",
        "\n",
        "Uses [Helsinki-NLP/opus-mt-ja-en](https://huggingface.co/Helsinki-NLP/opus-mt-ja-en) ‚Äî a lightweight MarianMT model for Japanese ‚Üí English. Fast and runs entirely on-device, but quality is limited for nuanced text. Honestly, this\n",
        "kinda sucks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9835ed59",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9835ed59",
        "outputId": "e98969ca-4f61-4099-9958-b14c3694b8df"
      },
      "outputs": [],
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "TRANSLATION_MODEL = \"Helsinki-NLP/opus-mt-ja-en\"\n",
        "\n",
        "print(f\"Loading translation model: {TRANSLATION_MODEL} ‚Ä¶\")\n",
        "trans_tokenizer = MarianTokenizer.from_pretrained(TRANSLATION_MODEL)\n",
        "trans_model = MarianMTModel.from_pretrained(TRANSLATION_MODEL).to(\"cuda\")\n",
        "print(\"‚úÖ Translation model loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f35fdc1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f35fdc1",
        "outputId": "b97e245d-39b8-4677-a94d-011f15469398"
      },
      "outputs": [],
      "source": [
        "def translate_texts(texts: list[str], batch_size: int = 32) -> list[str]:\n",
        "    \"\"\"Translate a list of Japanese texts to English in batches.\"\"\"\n",
        "    translations = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i : i + batch_size]\n",
        "        inputs = trans_tokenizer(\n",
        "            batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512\n",
        "        ).to(\"cuda\")\n",
        "        with torch.no_grad():\n",
        "            output_ids = trans_model.generate(**inputs, max_length=512)\n",
        "        decoded = trans_tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
        "        translations.extend(decoded)\n",
        "    return translations\n",
        "\n",
        "\n",
        "# Extract Japanese texts from subtitles\n",
        "ja_texts = [text for _, _, text in subtitles_ja]\n",
        "\n",
        "print(f\"Translating {len(ja_texts)} subtitle segments ‚Ä¶\")\n",
        "en_texts = translate_texts(ja_texts)\n",
        "print(\"‚úÖ Translation complete.\")\n",
        "\n",
        "# Build English subtitles with original timings\n",
        "subtitles_en = [\n",
        "    (start, end, en_text) for (start, end, _), en_text in zip(subtitles_ja, en_texts)\n",
        "]\n",
        "\n",
        "srt_en = build_srt(subtitles_en)\n",
        "\n",
        "# Save\n",
        "srt_en_path = f\"/content/{base_name}_en.srt\"\n",
        "with open(srt_en_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(srt_en)\n",
        "\n",
        "print(f\"\\n‚úÖ English SRT saved to: {srt_en_path}\")\n",
        "print(f\"   {len(subtitles_en)} subtitle segments\\n\")\n",
        "print(\"--- Preview (first 10 segments) ---\")\n",
        "print(\"\\n\".join(srt_en.split(\"\\n\")[:40]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QL3atzcfRbA1",
      "metadata": {
        "id": "QL3atzcfRbA1"
      },
      "source": [
        "## 6 ¬∑ Translate Subtitles with Gemini 3 Flash (free via Google AI Studio)\n",
        "\n",
        "Get an API key at https://aistudio.google.com/app/api-keys. By default, it uses\n",
        "a free tier, where billing isn't set up, so you shouldn't worry about getting\n",
        "charged. You can check the rate limits at https://aistudio.google.com/rate-limit?timeRange=last-28-days, and change the model accordingly.\n",
        "\n",
        "As of now, Gemini 3 Flash produces the highest quality translations (and are much higher-quality than the small opus-mt model ‚Äî especially for nuanced or conversational Japanese).\n",
        "\n",
        "**TODO: CHECK GOOGLE TRANSLATE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WQ6I9cTjRdm6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WQ6I9cTjRdm6",
        "outputId": "609c78b6-80c3-43aa-aaff-a3c715975e95"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "import json\n",
        "import time\n",
        "\n",
        "# Colab provides a free Gemini API key automatically\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    api_key = userdata.get(\"GOOGLE_API_KEY\")\n",
        "except userdata.SecretNotFoundError:\n",
        "    # Fallback: use the Colab-provided default\n",
        "    import os\n",
        "\n",
        "    api_key = os.environ.get(\"GOOGLE_API_KEY\", \"\")\n",
        "\n",
        "assert api_key, (\n",
        "    \"No Gemini API key found. In Colab, go to üîë Secrets (left sidebar) \"\n",
        "    \"and add GOOGLE_API_KEY.\"\n",
        ")\n",
        "\n",
        "genai.configure(api_key=api_key)\n",
        "gemini_model = genai.GenerativeModel(\"gemini-3-flash-preview\")\n",
        "\n",
        "SYSTEM_PROMPT = (\n",
        "    \"You are a professional Japanese-to-English subtitle translator. \"\n",
        "    \"You will receive numbered Japanese subtitle lines. \"\n",
        "    \"Return ONLY a JSON array of strings ‚Äî one English translation per line, \"\n",
        "    \"in the same order. Keep translations concise and natural for subtitles. \"\n",
        "    \"Preserve the original meaning and tone. Do NOT add numbering, extra text, \"\n",
        "    \"or unnecessary quotation marks.\"\n",
        ")\n",
        "\n",
        "\n",
        "def translate_with_gemini(\n",
        "    texts: list[str], batch_size: int = GEMINI_BATCH_SIZE\n",
        ") -> list[str]:\n",
        "    \"\"\"Translate Japanese texts to English using Gemini 3 Flash in batches.\"\"\"\n",
        "    all_translations = []\n",
        "\n",
        "    for batch_start in range(0, len(texts), batch_size):\n",
        "        batch = texts[batch_start : batch_start + batch_size]\n",
        "        batch_num = batch_start // batch_size + 1\n",
        "        total_batches = (len(texts) + batch_size - 1) // batch_size\n",
        "        print(f\"  Batch {batch_num}/{total_batches} ({len(batch)} lines) ‚Ä¶\", end=\" \")\n",
        "\n",
        "        # Build numbered input\n",
        "        numbered = \"\\n\".join(f\"{i + 1}. {t}\" for i, t in enumerate(batch))\n",
        "        prompt = f\"{SYSTEM_PROMPT}\\n\\nSubtitle lines:\\n{numbered}\"\n",
        "\n",
        "        for attempt in range(3):\n",
        "            try:\n",
        "                response = gemini_model.generate_content(prompt)\n",
        "                raw = response.text.strip()\n",
        "                # Strip markdown code fences if present\n",
        "                if raw.startswith(\"```\"):\n",
        "                    raw = raw.split(\"\\n\", 1)[1]\n",
        "                    raw = raw.rsplit(\"```\", 1)[0]\n",
        "                translations = json.loads(raw)\n",
        "                assert isinstance(translations, list) and len(translations) == len(\n",
        "                    batch\n",
        "                )\n",
        "                all_translations.extend(translations)\n",
        "                print(\"‚úÖ\")\n",
        "                break\n",
        "            except (json.JSONDecodeError, AssertionError, Exception) as e:\n",
        "                if attempt < 2:\n",
        "                    print(f\"‚ö†Ô∏è retry ({e.__class__.__name__}) ‚Ä¶\", end=\" \")\n",
        "                    time.sleep(2**attempt)\n",
        "                else:\n",
        "                    # Fallback: return originals for this batch\n",
        "                    print(f\"‚ùå fallback (kept Japanese)\")\n",
        "                    all_translations.extend(batch)\n",
        "\n",
        "        # Respect free-tier rate limits\n",
        "        if batch_start + batch_size < len(texts):\n",
        "            time.sleep(1)\n",
        "\n",
        "    return all_translations\n",
        "\n",
        "\n",
        "# --- Translate ---\n",
        "ja_texts_gemini = [text for _, _, text in subtitles_ja]\n",
        "print(f\"Translating {len(ja_texts_gemini)} subtitles with Gemini 3 Flash ‚Ä¶\\n\")\n",
        "en_texts_gemini = translate_with_gemini(ja_texts_gemini)\n",
        "print(f\"\\n‚úÖ Gemini translation complete.\")\n",
        "\n",
        "# Build English subtitles with original timings\n",
        "subtitles_en_gemini = [\n",
        "    (start, end, en_text)\n",
        "    for (start, end, _), en_text in zip(subtitles_ja, en_texts_gemini)\n",
        "]\n",
        "\n",
        "srt_en_gemini = build_srt(subtitles_en_gemini)\n",
        "\n",
        "# Save\n",
        "srt_en_gemini_path = f\"/content/{base_name}_en_gemini.srt\"\n",
        "with open(srt_en_gemini_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(srt_en_gemini)\n",
        "\n",
        "print(f\"‚úÖ Gemini English SRT saved to: {srt_en_gemini_path}\")\n",
        "print(f\"   {len(subtitles_en_gemini)} subtitle segments\\n\")\n",
        "print(\"--- Preview (first 10 segments) ---\")\n",
        "print(\"\\n\".join(srt_en_gemini.split(\"\\n\")[:40]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "130e65c2",
      "metadata": {
        "id": "130e65c2"
      },
      "source": [
        "## 7 ¬∑ Side-by-Side Comparison (opus-mt vs Gemini)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34e116ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34e116ee",
        "outputId": "b1db1bf7-71e9-417e-afce-8da442c744ea"
      },
      "outputs": [],
      "source": [
        "header = (\n",
        "    f\"{'#':>3}  {'Time':^27}  {'Japanese':<30}  {'opus-mt':<30}  {'Gemini 3 Flash':<30}\"\n",
        ")\n",
        "print(header)\n",
        "print(\"‚îÄ\" * len(header))\n",
        "for i, ((s, e, ja), (_, _, en_opus), (_, _, en_gem)) in enumerate(\n",
        "    zip(subtitles_ja, subtitles_en, subtitles_en_gemini), 1\n",
        "):\n",
        "    time_str = f\"{format_srt_time(s)} ‚Üí {format_srt_time(e)}\"\n",
        "    print(f\"{i:>3}  {time_str}  {ja:<30}  {en_opus:<30}  {en_gem:<30}\")\n",
        "    if i >= 30:\n",
        "        remaining = len(subtitles_ja) - 30\n",
        "        if remaining > 0:\n",
        "            print(f\"\\n... and {remaining} more segments.\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eef0a5d8",
      "metadata": {
        "id": "eef0a5d8"
      },
      "source": [
        "## 7 ¬∑ Download SRT Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59efb76b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "59efb76b",
        "outputId": "6ceed3f4-9372-411d-e1f4-ec2ca6b0ccec"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import files\n",
        "\n",
        "    print(\"Downloading Japanese SRT ‚Ä¶\")\n",
        "    files.download(srt_ja_path)\n",
        "    print(\"Downloading English SRT (opus-mt) ‚Ä¶\")\n",
        "    files.download(srt_en_path)\n",
        "    print(\"Downloading English SRT (Gemini) ‚Ä¶\")\n",
        "    files.download(srt_en_gemini_path)\n",
        "except ImportError:\n",
        "    print(\"Not running in Colab ‚Äî files saved at:\")\n",
        "    print(f\"  Japanese:        {srt_ja_path}\")\n",
        "    print(f\"  English (opus):  {srt_en_path}\")\n",
        "    print(f\"  English (Gemini): {srt_en_gemini_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea321c21",
      "metadata": {
        "id": "ea321c21"
      },
      "source": [
        "## 8 ¬∑ Cleanup (Optional)\n",
        "\n",
        "Free GPU memory if you want to run other things in this session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b5a3bf8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "3b5a3bf8",
        "outputId": "76ce00e3-6464-4931-ae5f-49ad8e862107"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "del trans_model, trans_tokenizer\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "print(\"‚úÖ GPU memory freed.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "030fbd75958d40f3bfb6986b632ca4f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2edae9b923f545c2ae09464fa18dd73f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44de2f6aa35f49109a55e4ad78d52268": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92b941db825d40a5a88c8954cff53dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_deb1e97276664d26a647a4c2681cac99",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b142015ef28340f9a7b6b0c571cd9297",
            "value": 2
          }
        },
        "9c0c0f539341452a9ea60137b28cb249": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2edae9b923f545c2ae09464fa18dd73f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_aaecbd66f31246ddb27ebf19d50694a2",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "aa7a8cfe307c413b92607e4cf1754ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44de2f6aa35f49109a55e4ad78d52268",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b82a844a83e94c3db3e37d2583edd546",
            "value": "‚Äá2/2‚Äá[00:18&lt;00:00,‚Äá‚Äá7.89s/it]"
          }
        },
        "aaecbd66f31246ddb27ebf19d50694a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b142015ef28340f9a7b6b0c571cd9297": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b82a844a83e94c3db3e37d2583edd546": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d55e7b10d1544ecc8503cdf363732622": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c0c0f539341452a9ea60137b28cb249",
              "IPY_MODEL_92b941db825d40a5a88c8954cff53dbb",
              "IPY_MODEL_aa7a8cfe307c413b92607e4cf1754ffe"
            ],
            "layout": "IPY_MODEL_030fbd75958d40f3bfb6986b632ca4f3"
          }
        },
        "deb1e97276664d26a647a4c2681cac99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
